{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8533dd4",
   "metadata": {},
   "source": [
    "# Scripts for ChroMo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b51cb4",
   "metadata": {},
   "source": [
    "This notebook includes the essential programs for processing and merging the files generated by the Fiji segmentation macro. The resulting files are specifically designed for ChroMo image analysis.\n",
    "\n",
    "The script incorporates a linear velocity column and, if desired, performs time normalization. Additionally, it includes the necessary script to generate the horsetail and stop values files based on the linear velocity column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e0ed35",
   "metadata": {},
   "source": [
    "### Script to process, merge and extract the horsetail movement stage from the CSV files generated by the Fiji macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dda19ca3",
   "metadata": {
    "code_folding": [
     10
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join, basename\n",
    "from tkinter import Tk, Label, Entry, Button, filedialog, font, Text, BooleanVar, Checkbutton\n",
    "from pandas import read_csv, concat, DataFrame\n",
    "from pandas.errors import ParserError\n",
    "from math import sqrt\n",
    "from glob import glob\n",
    "from configparser import ConfigParser\n",
    "\n",
    "\n",
    "def process_for_ChroMo():\n",
    "    '''\n",
    "    Initializes the program to process, merge and generate the horsetail and stop files. \n",
    "    '''\n",
    "    def browse_folder_path():\n",
    "        folder_path = filedialog.askdirectory()\n",
    "        path_entry.delete(0, 'end')\n",
    "        path_entry.insert('end', folder_path)\n",
    "\n",
    "    def browse_folder_save():\n",
    "        folder_path = filedialog.askdirectory()\n",
    "        save_path_entry.delete(0, 'end')\n",
    "        save_path_entry.insert('end', folder_path)\n",
    "\n",
    "    # Create an instance of ConfigParser\n",
    "    config = ConfigParser()\n",
    "\n",
    "    # Load the configuration file\n",
    "    config.read('last_arguments_process.ini')\n",
    "\n",
    "    def process_files(path, save_path, var_label, pattern, cal_speed,\n",
    "                      normalize):\n",
    "        '''\n",
    "        Processes the files generated by the Fiji macro. It detects the frame where the cell is dividing and \n",
    "        changes the columns so that ChroMo can detect each parameter. \n",
    "\n",
    "        Arguments:\n",
    "        - path (string): the path where the files generated by the Fiji macro are located. \n",
    "        - save_path (string): the path where you want to save the results. \n",
    "        - var_label (string): the name that you want to associate with the cell group, by default the strain name.\n",
    "        - pattern (string): the pattern used to identify the files to process. }\n",
    "        - cal_speed (bool): if checked (changing the default value to True), the function calculates linear velocity.\n",
    "        - normalize (bool): if checked (changing the default value to True), the function does time normalization.\n",
    "        '''\n",
    "\n",
    "        pattern = pattern.lower()\n",
    "\n",
    "        files = glob(join(path, f'*{pattern}*'))\n",
    "\n",
    "        result_text.configure(state=\"normal\")\n",
    "        result_text.delete('1.0', 'end')  # Clear the previous results\n",
    "\n",
    "        # Frame of division check\n",
    "        for file in files:\n",
    "            try:\n",
    "                df = read_csv(file)\n",
    "            except ParserError:\n",
    "                result_text.insert('end', f\"Error reading file: {file}\\n\")\n",
    "                continue\n",
    "\n",
    "            frame_delete = df[df['Label'].str.contains(\n",
    "                r'[0-9]{4}-0002-[0-9]{4}')].index\n",
    "\n",
    "            if len(frame_delete) > 0:\n",
    "                result_text.insert(\n",
    "                    'end', f\"First frame deleted: {frame_delete[0]}\\n\")\n",
    "                df = df.loc[:frame_delete[0] - 1]\n",
    "            else:\n",
    "                result_text.insert('end', \"No matching rows found.\\n\")\n",
    "\n",
    "            save_file = join(save_path,\n",
    "                             basename(file).replace(\".csv\", \"_processed.csv\"))\n",
    "            df.to_csv(save_file, index=False)\n",
    "\n",
    "        files = glob(join(save_path, f'*{pattern}*'))\n",
    "\n",
    "        result_text.insert('end', \"\\nFiles saved in the folder:\\n\")\n",
    "        result_text.insert('end', \"\\n\".join(basename(file) for file in files))\n",
    "\n",
    "        # Calculates linear velocity used below\n",
    "        def vector_magnitude(x1, y1, x2, y2):\n",
    "            dx = x2 - x1\n",
    "            dy = y2 - y1\n",
    "            magnitude = sqrt(dx**2 + dy**2)\n",
    "            return magnitude\n",
    "\n",
    "        # This code changes the column names so ChroMo can automatically detect each parameter.\n",
    "        for file in files:\n",
    "            x = read_csv(file)\n",
    "            x.columns = [\n",
    "                \"frame\", \"particle\", \"area\", \"x\", \"y\", \"XM\", \"YM\", \"perimeter\",\n",
    "                \"major\", \"minor\", \"Angle\", \"circularity\", \"frame.1\", \"AR\",\n",
    "                \"Roundness\", \"convexity\"\n",
    "            ]\n",
    "            x['label'] = var_label\n",
    "            x['particle'] = x['particle'].str.split(\"_R3D\").str[0][0]\n",
    "            x_subset = x.iloc[:, [0, 1, 2, 3, 4, 8, 9, 11, 15, 16]].copy()\n",
    "            save_file = join(save_path, basename(file))\n",
    "            x_subset.to_csv(save_file, index=False)\n",
    "\n",
    "            # this code adds the column 'cal.speed' with the values of linear velocity of each frame\n",
    "            if cal_speed == True:\n",
    "                x1, y1, x2, y2 = None, None, None, None\n",
    "                for index, row in x_subset.iterrows():\n",
    "                    if index > 0:\n",
    "                        if x2 is None:\n",
    "                            x2 = row['x']\n",
    "                            y2 = row['y']\n",
    "                        else:\n",
    "                            x1 = x2\n",
    "                            y1 = y2\n",
    "                            x2 = row['x']\n",
    "                            y2 = row['y']\n",
    "                            magnitude = vector_magnitude(x1, y1, x2, y2)\n",
    "                            x_subset.loc[\n",
    "                                index - 1,\n",
    "                                'cal.speed'] = magnitude  # Assign the magnitude to the previous row\n",
    "\n",
    "                x_subset = x_subset.iloc[1:\n",
    "                                         -1]  # Remove the first and last rows\n",
    "\n",
    "                save_file = join(save_path, basename(file))\n",
    "                x_subset.to_csv(save_file, index=False)\n",
    "\n",
    "            # Time normalization\n",
    "            if normalize == True:\n",
    "                x_subset['frame'] = (range(-1, -len(x_subset['frame']) - 1,\n",
    "                                           -1))\n",
    "                x_subset['frame'] = x_subset['frame'].sort_values().values\n",
    "\n",
    "                x_subset.to_csv(save_file, index=False)\n",
    "\n",
    "        # Save the arguments to the configuration file\n",
    "        config['LastArgs'] = {\n",
    "            'path': path,\n",
    "            'save_path': save_path,\n",
    "            'var_label': var_label,\n",
    "            'pattern': pattern\n",
    "        }\n",
    "        with open('last_arguments_process.ini', 'w') as configfile:\n",
    "            config.write(configfile)\n",
    "\n",
    "        result_text.configure(\n",
    "            state=\"disabled\"\n",
    "        )  #so that the user cannot edit the results window.\n",
    "\n",
    "    def merge_files(\n",
    "        path_processed_files,\n",
    "        csv_name,\n",
    "        pattern,\n",
    "    ):\n",
    "        '''\n",
    "        Merges the processed files generated by the process_files program. \n",
    "\n",
    "        Arguments:\n",
    "        - path_processed_files (string): the path where the processed files are and where the merged file is saved. \n",
    "        - csv_name (string): the name you want to assign to the merged file.\n",
    "        - pattern (string): the pattern used to identify the files to merge. \n",
    "        '''\n",
    "\n",
    "        result_text_merge.configure(state='normal')\n",
    "        result_text_merge.delete('1.0', 'end')  # Clear the previous results\n",
    "\n",
    "        files = [\n",
    "            f for f in listdir(path_processed_files)\n",
    "            if f.lower().endswith(\".csv\") and pattern.lower() in f.lower()\n",
    "        ]\n",
    "\n",
    "        total = None\n",
    "\n",
    "        for csv in files:\n",
    "            csv_cell = join(path_processed_files, csv)\n",
    "            result_text_merge.insert(\n",
    "                'end',\n",
    "                f\"Location of the merged .csv:\\n {csv_cell} -> merged :) \\n\"\n",
    "            )  # This prints the location and name of the merged .csv\n",
    "            df = read_csv(csv_cell)\n",
    "\n",
    "            if total is None:\n",
    "                total = df\n",
    "            else:\n",
    "                total = concat([total, df], ignore_index=True)\n",
    "\n",
    "        csv_name2 = csv_name + \".csv\"\n",
    "        csv = join(path_processed_files, csv_name2)\n",
    "        total.to_csv(csv, index=False)\n",
    "\n",
    "        # Save the arguments to the configuration file\n",
    "        config['LastArgsMerge'] = {\n",
    "            'path_processed_files': path_processed_files,\n",
    "            'csv_name': csv_name,\n",
    "            'pattern_merge': pattern\n",
    "        }\n",
    "        with open('last_arguments_process.ini', 'w') as configfile:\n",
    "            config.write(configfile)\n",
    "\n",
    "        result_text_merge.configure(\n",
    "            state='disabled'\n",
    "        )  #so that the user cannot edit the results window.\n",
    "\n",
    "    def detect_horsetail(path, csv_filename, speed_stop_threshold):\n",
    "        '''\n",
    "        Detects the horsetail and stop values given the linear velocities. \n",
    "\n",
    "            Arguments:\n",
    "            - path (string): the path where the files generated by the Fiji macro are located. \n",
    "            - csv_filename (string): the filename of the csv file to analyze.\n",
    "            - speed_stop_threshold (float): the velocity value to detect the stop cell movement.\n",
    "        '''\n",
    "        speed_stop_threshold = float(speed_stop_threshold)\n",
    "        \n",
    "        result_text_horsetail.configure(state='normal')\n",
    "        result_text_horsetail.delete('1.0', 'end')  # Clear the previous results\n",
    "        \n",
    "        # Read the csv and look for the column cal.speed\n",
    "        try:\n",
    "            df = read_csv(path + '/' + csv_filename + '.csv')\n",
    "            velocity_column = 'cal.speed'\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            result_text_horsetail.insert('end', 'The CSV file was not found.')\n",
    "            return\n",
    "\n",
    "        if velocity_column not in df.columns:\n",
    "            result_text_horsetail.insert('end', f\"The '{velocity_column}' column is not in the CSV; you must calculate the linear velocity first.\")\n",
    "            return\n",
    "\n",
    "        # Loop\n",
    "        particle = []\n",
    "        durationHT = []\n",
    "        durationPosHT = []\n",
    "        position = 0\n",
    "\n",
    "        for i in df['particle'].unique():\n",
    "            cell = df[df['particle'] == i]\n",
    "            a = []\n",
    "            j = 0\n",
    "\n",
    "            while sum(a) < 6:\n",
    "                vector = cell[velocity_column][j:j + 6]\n",
    "                a = [1 if v < speed_stop_threshold else 0 for v in vector]\n",
    "                \n",
    "                if vector.empty:\n",
    "                    result_text_horsetail.insert('end',f\"Particle: {i} stop not detected.\\n \\n\")\n",
    "                    break\n",
    "                \n",
    "                j += 1\n",
    "\n",
    "            durationHT.append(j + 1)\n",
    "            durationPosHT.append(len(cell['frame']) - j - 1)\n",
    "            particle.append(i)\n",
    "            position += 1\n",
    "\n",
    "        # Horsetail values file\n",
    "        data = DataFrame({\n",
    "            'particle': particle,\n",
    "            'durationHT': durationHT,\n",
    "            'durationPosHT': durationPosHT\n",
    "        })\n",
    "\n",
    "        # Incorrect particle stop processing\n",
    "        data.loc[data['durationPosHT'] == 3, 'durationHT'] += 3\n",
    "        data.loc[data['durationPosHT'] == 3, 'durationPosHT'] = 0\n",
    "\n",
    "        # Save final data\n",
    "        data.to_csv(path + '/' + csv_filename + '_stop.csv', index=False)\n",
    "\n",
    "        # Read the csv file processed with chromo\n",
    "        df = read_csv(path + '/' + csv_filename + '.csv')\n",
    "\n",
    "        # Read the file generated in the previous step\n",
    "        df_stop_values = read_csv(path + '/' + csv_filename + '_stop.csv')\n",
    "\n",
    "        vector_stop_values = []\n",
    "        for i in df_stop_values['particle'].unique():\n",
    "            vector_stop_values.extend(\n",
    "                df_stop_values.loc[df_stop_values['particle'] == i,\n",
    "                                   'durationPosHT'])\n",
    "\n",
    "        df_subset = df.copy()\n",
    "\n",
    "        all_cells = []\n",
    "        for i in df_subset['particle'].unique():\n",
    "            all_cells.extend(df_subset.loc[df_subset['particle'] == i,\n",
    "                                           'particle'].unique())\n",
    "\n",
    "        # Delete the posthorsetail phase\n",
    "        n = 0\n",
    "        out_df = df_subset.copy()\n",
    "\n",
    "        for i in df['particle'].unique():\n",
    "            n += 1\n",
    "            out_df = out_df[~((out_df['frame'] > -vector_stop_values[n - 1]) &\n",
    "                              (out_df['particle'] == i))]\n",
    "\n",
    "        out_df.to_csv(path + '/' + csv_filename + '_horsetail.csv', index=False)\n",
    "        \n",
    "        # Display the path of the files.\n",
    "        pattern = csv_filename\n",
    "        files = [\n",
    "            f for f in listdir(path)\n",
    "            if f.lower().endswith(\".csv\") and pattern.lower() in f.lower()\n",
    "        ]\n",
    "\n",
    "        for csv in files:\n",
    "            csv_cell = join(path, csv)\n",
    "            result_text_horsetail.insert(\n",
    "                    'end',\n",
    "                    f\"Location of the file:\\n {csv_cell} \\n\"\n",
    "                ) \n",
    "\n",
    "        # Save the arguments to the configuration file\n",
    "        config['LastArgsHorsetail'] = {\n",
    "            'path': path,\n",
    "            'csv_filename': csv_filename,\n",
    "            'speed_stop_threshold': speed_stop_threshold\n",
    "        }\n",
    "        with open('last_arguments_process.ini', 'w') as configfile:\n",
    "            config.write(configfile)\n",
    "\n",
    "        result_text_horsetail.configure(\n",
    "            state='disabled'\n",
    "        )  #so that the user cannot edit the results window.\n",
    "        \n",
    "    # Read the last arguments from the configuration file\n",
    "    last_path = config.get('LastArgs', 'path', fallback='')\n",
    "    last_save_path = config.get('LastArgs', 'save_path', fallback='')\n",
    "    last_var_label = config.get('LastArgs', 'var_label', fallback='')\n",
    "    last_pattern_process = config.get('LastArgs', 'pattern', fallback='')\n",
    "\n",
    "    # Create the main window\n",
    "    root = Tk()\n",
    "    root.geometry(\"1100x900\")\n",
    "    root.title(\"Fiji Files Processor, Merger and Horsetail Detector\")\n",
    "    root.configure(bg=\"#95C8F3\")\n",
    "\n",
    "    # Configure the grid to adjust widget positions\n",
    "    root.grid_columnconfigure(index=15, weight=1)\n",
    "    root.grid_rowconfigure(index=11, weight=1)\n",
    "\n",
    "    # Create labels and entry fields for input\n",
    "    button_font = font.Font(family=\"Comic Sans MS\", size=10)\n",
    "\n",
    "    Label(root, text=\"Path:\", font=button_font, bg=\"#95C8F3\").grid(row=0,\n",
    "                                                                   column=0,\n",
    "                                                                   sticky='e')\n",
    "    path_entry = Entry(root)\n",
    "    path_entry.grid(row=0, column=1, sticky=\"we\")\n",
    "    Button(root,\n",
    "           text=\"Browse\",\n",
    "           command=browse_folder_path,\n",
    "           bg='#AEB5FF',\n",
    "           fg='black',\n",
    "           font=button_font).grid(row=0, column=2, sticky='we')\n",
    "\n",
    "    Label(root, text=\"Save Path:\", font=button_font,\n",
    "          bg=\"#95C8F3\").grid(row=1, column=0, sticky='e')\n",
    "    save_path_entry = Entry(root)\n",
    "    save_path_entry.grid(row=1, column=1, sticky=\"we\")\n",
    "    Button(root,\n",
    "           text=\"Browse\",\n",
    "           command=browse_folder_save,\n",
    "           bg='#AEB5FF',\n",
    "           fg='black',\n",
    "           font=button_font).grid(row=1, column=2, sticky='we')\n",
    "\n",
    "    Label(root, text=\"Variable Label:\", font=button_font,\n",
    "          bg=\"#95C8F3\").grid(row=2, column=0, sticky='e')\n",
    "    var_label_entry = Entry(root)\n",
    "    var_label_entry.grid(row=2, column=1, sticky='we')\n",
    "\n",
    "    Label(root, text=\"Pattern:\", font=button_font,\n",
    "          bg=\"#95C8F3\").grid(row=3, column=0, sticky='e')\n",
    "    pattern_entry = Entry(root)\n",
    "    pattern_entry.grid(row=3, column=1, sticky='we')\n",
    "\n",
    "    root.grid_columnconfigure(1, weight=5)\n",
    "\n",
    "    # Set the last arguments as default values in the entry fields\n",
    "    path_entry.insert('end', last_path)\n",
    "    save_path_entry.insert('end', last_save_path)\n",
    "    var_label_entry.insert('end', last_var_label)\n",
    "    if not last_pattern_process:\n",
    "        pattern_entry.insert('end', \"Results\") #default value\n",
    "    else:\n",
    "        pattern_entry.insert('end', last_pattern_process)\n",
    "\n",
    "    # Create a variable to store the checkbox state\n",
    "    cal_speed_state = BooleanVar()\n",
    "    cal_speed_state.set(False)  # Set the initial state to unchecked\n",
    "\n",
    "    # Function to toggle the checkbox state\n",
    "    def toggle_cal_speed():\n",
    "        cal_speed_state.get() == True\n",
    "\n",
    "    # Create the checkbox\n",
    "    checkbox = Checkbutton(root,\n",
    "                           text='Linear Velocity',\n",
    "                           variable=cal_speed_state,\n",
    "                           onvalue=True,\n",
    "                           offvalue=False,\n",
    "                           command=toggle_cal_speed,\n",
    "                           bg='#AEB5FF',\n",
    "                           font=button_font)\n",
    "    checkbox.grid(row=4, column=0, columnspan=3, sticky='w')\n",
    "\n",
    "    # Create a variable to store the checkbox state\n",
    "    normalize_state = BooleanVar()\n",
    "    normalize_state.set(False)  # Set the initial state to unchecked\n",
    "\n",
    "    # Function to toggle the checkbox state\n",
    "    def toggle_normalize():\n",
    "        normalize_state.get() == True\n",
    "\n",
    "    # Create the checkbox\n",
    "    checkbox = Checkbutton(root,\n",
    "                           text='Time Normalization',\n",
    "                           variable=normalize_state,\n",
    "                           onvalue=True,\n",
    "                           offvalue=False,\n",
    "                           command=toggle_normalize,\n",
    "                           bg='#AEB5FF',\n",
    "                           font=button_font)\n",
    "    checkbox.grid(row=5, column=0, columnspan=3, sticky='w')\n",
    "\n",
    "    # Create a button to process the files\n",
    "    process_button = Button(\n",
    "        root,\n",
    "        text=\"Process Files\",\n",
    "        command=lambda: process_files(path_entry.get(), save_path_entry.get(\n",
    "        ), var_label_entry.get(), pattern_entry.get(), cal_speed_state.get(),\n",
    "                                      normalize_state.get()),\n",
    "        font=font.Font(family=\"Comic Sans MS\", size=11, weight=\"bold\"),\n",
    "        bg='#7DE198',\n",
    "        fg='black')\n",
    "    process_button.grid(row=6, column=0, columnspan=3, sticky='we')\n",
    "\n",
    "    # Create a text widget to display the results of the processing.\n",
    "    results_font = font.Font(family=\"MS Serif\", size=11)\n",
    "    result_text = Text(root, height=10, width=50, font=results_font)\n",
    "    result_text.grid(row=7, column=0, columnspan=3, sticky='nsew')\n",
    "    result_text.configure(bg=\"#81E3E1\", fg=\"black\", state=\"normal\")\n",
    "\n",
    "    # Read the last merge arguments from the configuration file\n",
    "    last_path_processed_files = config.get('LastArgsMerge',\n",
    "                                           'path_processed_files',\n",
    "                                           fallback='')\n",
    "    last_csv_name = config.get('LastArgsMerge', 'csv_name', fallback='')\n",
    "    last_pattern_merge = config.get('LastArgsMerge',\n",
    "                                    'pattern_merge',\n",
    "                                    fallback='')\n",
    "\n",
    "    # Create labels and entry fields for input of the merging function.\n",
    "    button_font = font.Font(family=\"Comic Sans MS\", size=10)\n",
    "\n",
    "    Label(root, text=\"Merged CSV name:\", font=button_font,\n",
    "          bg=\"#95C8F3\").grid(row=8, column=0, sticky='e')\n",
    "    csv_name_entry = Entry(root)\n",
    "    csv_name_entry.grid(row=8, column=1, sticky='we')\n",
    "\n",
    "    Label(root, text=\"Pattern:\", font=button_font,\n",
    "          bg=\"#95C8F3\").grid(row=9, column=0, sticky='e')\n",
    "    pattern_merge_entry = Entry(root)\n",
    "    pattern_merge_entry.grid(row=9, column=1, sticky='we')\n",
    "\n",
    "    root.grid_columnconfigure(1, weight=5)\n",
    "\n",
    "    # Set the last arguments as default values in the merge entry fields\n",
    "    csv_name_entry.insert('end', last_csv_name)\n",
    "    pattern_merge_entry.insert('end', last_pattern_merge)\n",
    "\n",
    "    # Create a button to merge the files\n",
    "    merge_button = Button(\n",
    "        root,\n",
    "        text=\"Merge Files\",\n",
    "        command=lambda: merge_files(save_path_entry.get(), csv_name_entry.get(\n",
    "        ), pattern_merge_entry.get()),\n",
    "        font=font.Font(family=\"Comic Sans MS\", size=11, weight=\"bold\"),\n",
    "        bg='#7DE198',\n",
    "        fg='black')\n",
    "    merge_button.grid(row=10, column=0, columnspan=3, sticky='we')\n",
    "\n",
    "    # Create a text widget to display the results of the merge.\n",
    "    result_text_merge = Text(root, height=10, width=50, font=results_font)\n",
    "    result_text_merge.grid(row=11, column=0, columnspan=3, sticky='nsew')\n",
    "    result_text_merge.configure(bg=\"#81E3E1\", fg=\"black\", state=\"normal\")\n",
    "    \n",
    "    # Read the last horsetail arguments from the configuration file\n",
    "    last_path_horsetail = config.get('LastArgsHorsetail',\n",
    "                                           'path',\n",
    "                                           fallback='')\n",
    "    last_name_horsetail = config.get('LastArgsHorsetail', 'csv_filename', fallback='')\n",
    "    last_threshold = config.get('LastArgsHorsetail',\n",
    "                                    'speed_stop_threshold',\n",
    "                                    fallback='') \n",
    "\n",
    "    # Create labels and entry fields for input\n",
    "    button_font = font.Font(family=\"Comic Sans MS\", size=10)\n",
    "\n",
    "    Label(root, text=\"Name of the CSV:\", font=button_font,\n",
    "          bg=\"#95C8F3\").grid(row=4, column=14, sticky='e')\n",
    "    csv_horsetail_entry = Entry(root)\n",
    "    csv_horsetail_entry.grid(row=4, column=15, sticky='we')\n",
    "\n",
    "    Label(root, text=\"Speed stop threshold:\", font=button_font,\n",
    "          bg=\"#95C8F3\").grid(row=5, column=14, sticky='e')\n",
    "    threshold_entry = Entry(root)\n",
    "    threshold_entry.grid(row=5, column=15, sticky='we')\n",
    "\n",
    "    root.grid_columnconfigure(1, weight=5)\n",
    "\n",
    "    # Set the last arguments as default values in the entry fields\n",
    "    csv_horsetail_entry.insert('end', last_name_horsetail)\n",
    "    if not last_threshold:\n",
    "        threshold_entry.insert('end', 0.2992296) #default value\n",
    "    else:\n",
    "        threshold_entry.insert('end', last_threshold)\n",
    "\n",
    "    # Create a button to detect the horsetail and stop values\n",
    "    horsetail_button = Button(\n",
    "        root,\n",
    "        text=\"Detect Horsetail\",\n",
    "        command=lambda: detect_horsetail(save_path_entry.get(), csv_horsetail_entry.get(\n",
    "        ), float(threshold_entry.get())),\n",
    "        font=font.Font(family=\"Comic Sans MS\", size=11, weight=\"bold\"),\n",
    "        bg='#7DE198',\n",
    "        fg='black')\n",
    "    horsetail_button.grid(row=6, column=14, columnspan=3, sticky='we')\n",
    "\n",
    "    # Create a text widget to display the results\n",
    "    result_text_horsetail = Text(root, height=10, width=50, font=results_font)\n",
    "    result_text_horsetail.grid(row=7, column=14, columnspan=3, rowspan=10,sticky='nsew')\n",
    "    result_text_horsetail.configure(bg=\"#81E3E1\", fg=\"black\", state=\"normal\")\n",
    "    \n",
    "    root.mainloop()\n",
    "\n",
    "\n",
    "# Run the function to start the application\n",
    "process_for_ChroMo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
